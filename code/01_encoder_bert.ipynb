{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c74fe53-3a77-487c-bf59-177f98d52642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "yD6y2CEQtrNW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8cb6f95-327e-4978-9007-b2a58a7f3167",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718,
     "referenced_widgets": [
      "a0336d38a34e4454bd16cebc540b3d99",
      "e517eab811bf44b1850678a3934f96c6",
      "fec6e161fac84f529d386b189ac1e52c",
      "b5160145b6ba4fcd8df582948dcb9b72",
      "5deadd37e411425babf0897369e59cc4",
      "b35606c1919a417990248696b880f15f",
      "876d0feafe8c4009a5e7043ca84d433a",
      "147a14d0bc234233843e3007ecb5a020",
      "ec05d670c3c044a595068480da4f5c4e",
      "1e2211a5d7e848efbaf4f5b68e2a732e",
      "df408f096a7747868a76200c672d51d1",
      "5aab56208f2546ce99afd090125ef179",
      "bff0267096eb411e8ab696c7ed8f05a4",
      "fa7585c43a7c4849a60c5c6522d531fa",
      "f16f1bb348224bff83453a88f1e3b048",
      "d52a15b5aa1942fca502e38de62faf41",
      "abe50625897643b4ba6f50d4d69dd42c",
      "051863554835420ab3b9ee5e4530cd75",
      "a00e985609eb4a4c86c8e55e41ac60cd",
      "1015459bb5f549e8b198860da6433820",
      "36b4175a2d964e43af8c07a2ddc5fd6d",
      "95728426f4544536af965893cce2af29",
      "4403ae53d4e4410f837a738fbbdef8c6",
      "25eabb35145c4bc8ab27735b71dde2e6",
      "c53ea25e78114227b1e868bd4d8db9f6",
      "99aa8f16eeac410facc931357367b834",
      "d78b740ef4d444c9a4f1c3871d02bcd3",
      "0d7fcacdcb4440f0996faa26b42f964c",
      "e3b85eab756e4ce5b2664cdeeb538ff3",
      "ae5ab90c4fc444e6b8c9e2d72a255802",
      "b1194bff113249bc88b7beb29106c1db",
      "0a8495df89a748b69b7f1bb845be5fcd",
      "a9a5601333f64934bb5fe89b730ed9bc",
      "d1e92b7868e146d590febeac3ef18200",
      "9aaf674c6491442d8d10671f66d2b182",
      "4801de157d0b4ddda4b01606452c00d7",
      "5a32c0e89ef8469f8e0f5e49012ba249",
      "eddff6e676e84441a249db3679361884",
      "c4afddde8ac94285b36b52b69ee5aa02",
      "77e5d2ef71c549449fbfd2ef5123275b",
      "285ff46a9d2c4f10aa0fddc2e9b151d3",
      "b9e62b86fc544041a90db411635070cf",
      "1a2b31bc883b43c891a545f44ece6a53",
      "2ae075e0465f4f7ab0138ca938416a92",
      "60d0a9d14e174a8cb721f576c145c00d",
      "0beb06c937784f449c849f08d2c74511",
      "964c2d9d1ddd4626a5e0247e3daa769c",
      "a4b7e8be8b7f4fc4bb0422abb044b3e6",
      "6352b709d896402d83f9b615a0827781",
      "407846abb95747b09afac12d6b22a46a",
      "56fd9dec61db4c2cbd009c3729b05e80",
      "b7786210b0b348dc95b76358ef843e3d",
      "65d534c712ee42c587b359dec4ce86e8",
      "9e32920efba149d3a1e3566c6fe776e8",
      "8f7748025a71433e818986d929a0e185"
     ]
    },
    "id": "8IEM7wgDtrNX",
    "outputId": "5f95b328-d801-4201-c1be-cdde6842d086"
   },
   "outputs": [],
   "source": [
    "# The pipeline('fill-mask') automatically loads a pretrained masked-language model.\n",
    "# BERT predicts the missing [MASK] token\n",
    "# result contains a list of top token predictions with probabilities.\n",
    "\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "\n",
    "test = \"Every morning last summer in Greece, \" + \\\n",
    "       \"I visited the [MASK] where I would swim, \" + \\\n",
    "       \"play in the sand, and sunbathe.\"\n",
    "\n",
    "result = unmasker(test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aefc923e-c6c2-4646-8133-cf87f3442eb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_OoutOxotrNX"
   },
   "source": [
    "## Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73c9f22d-68ad-479c-9e0d-226463455007",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XHlkqEY7trNX"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.dropbox.com/scl/fi/i2esmtinb4qor0mzokybp/fed_sentiment_training.csv?rlkey=v9u7afunmy8w0v0lwizba5g25&dl=1'\n",
    "df = pd.read_csv(url, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c23d64a5-3f72-413d-b3bf-8a39ce6714e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "JwoMgHsEtrNX",
    "outputId": "829001d2-71bd-4300-eff9-140b12e67df7"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04b240b0-9a91-44c4-b851-2976d4e58494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "sIOrrwMetrNX",
    "outputId": "82346e34-cfba-4847-ba3c-87292c6ba12e"
   },
   "outputs": [],
   "source": [
    "df.loc[0, \"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdb011eb-0c9e-4730-bbbb-ef4d90d44562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MEjfRSwttrNX"
   },
   "source": [
    "### Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08d976e9-196a-42e7-85c9-5c671fbdb5fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iR0yLMV_trNX",
    "outputId": "a3d34093-2577-4c35-c72a-a89beac780b9"
   },
   "outputs": [],
   "source": [
    "# Loads the same tokenizer that BERT was trained with.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer # [PAD] is used to pad the text to the max length 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9d153b1-66da-4ef0-b077-07dc0eb55a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0pDTIvetrNX",
    "outputId": "733af71c-4298-4821-f2ba-abb784668dab"
   },
   "outputs": [],
   "source": [
    "# The tokenizer’s vocabulary contains about 30,000 subword tokens.\n",
    "# Subword tokens look like un, ##happy, etc.\n",
    "# Each has a unique integer ID that BERT uses internally.\n",
    "\n",
    "vocab = tokenizer.get_vocab()\n",
    "print(f\"Total number of tokens in vocabulary: {len(vocab)} \\n---------\")\n",
    "for _ in range(10): # Repeats the process 10 times but I am not going to use the loop variable\n",
    "    word, idx = random.choice(list(vocab.items()))\n",
    "    print(word, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5ee257e-756d-451c-83c2-fd29e89b8ad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "hEPOW3vLtrNX"
   },
   "outputs": [],
   "source": [
    "# takes one text string (the first row) and converts it into tensors suitable for BERT.\n",
    "encoded_input1 = tokenizer(df.loc[0, \"text\"],\n",
    "                           max_length=100,\n",
    "                           padding=\"max_length\",\n",
    "                           return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fjsra2hGY51o",
    "outputId": "ace4c4fc-2d36-4a36-e231-8be670915637"
   },
   "outputs": [],
   "source": [
    "encoded_input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUMWCkDJZAPQ",
    "outputId": "cf6058ca-34cf-42f4-8b23-e61f76d6bd92"
   },
   "outputs": [],
   "source": [
    "# Each number corresponds to a token ID in BERT’s 30k-word vocabulary.\n",
    "# tensor of shape [1, 100]\n",
    "encoded_input1.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVe8gcHoZpix",
    "outputId": "778dabb5-906c-4037-86b9-548e95e091f4"
   },
   "outputs": [],
   "source": [
    "# This tells BERT which tokens are real and which are padding.\n",
    "# 1 → real token (to be attended to)\n",
    "# 0 → padding token (ignore it)\n",
    "\n",
    "encoded_input1.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVldE22IY8Or",
    "outputId": "8322b143-126c-4e4e-e08b-d79757f15adf"
   },
   "outputs": [],
   "source": [
    "# 1D tensor of shape [100]\n",
    "temp_tokens = encoded_input1[\"input_ids\"][0]  # ← Add [0] here to get first sequence\n",
    "print(\"Tokens IDs:\")\n",
    "print(temp_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfCzyTsTa7cl",
    "outputId": "741fad00-2c58-43a6-87d8-dec58a4a190d"
   },
   "outputs": [],
   "source": [
    "# translates those integer IDs back into their string tokens — i.e., the subwords that BERT uses internally.\n",
    "print(\"\\n------------------------------------------\\n\")\n",
    "print(\"Tokens:\")\n",
    "print(tokenizer.convert_ids_to_tokens(temp_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dceb3e85-a502-4483-8eb0-794c25993392",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Dgku4SBstrNY"
   },
   "source": [
    "### Obtaining Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cfebb8b-6e08-4970-9a8c-288d0f638229",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gP5gxXMytrNY",
    "outputId": "e8d9bb8c-3bfe-4330-a123-dd07577ab39d"
   },
   "outputs": [],
   "source": [
    "# Loads the pretrained BERT model weights.\n",
    "# Each input token will be represented by a 768-dimensional embedding at each layer.\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\",\n",
    "                                  output_hidden_states=True, # keeps internal layer outputs.\n",
    "                                  output_attentions=True, # keeps attention matrices\n",
    "                                  attn_implementation=\"eager\"\n",
    "                                  )\n",
    "\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb6d53ed-95f4-4281-b31f-e3b42b0b52a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ifn_3XNHtrNY"
   },
   "outputs": [],
   "source": [
    "# Step 1: Get BERT output without computing gradients (inference mode)\n",
    "# Disables gradient tracking (saves memory & compute). Normally, PyTorch builds\n",
    "# a computation graph during forward passes so it can later compute gradients (for training).\n",
    "with torch.no_grad():\n",
    "    result1 = model(**encoded_input1)\n",
    "    # The ** operator unpacks the dictionary into keyword arguments\n",
    "    # ** (double star) → unpacks a dictionary into keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHs9aXY4fgmA",
    "outputId": "8cc6b06d-3226-4ce1-b6fe-e7fc819513f5"
   },
   "outputs": [],
   "source": [
    "def greet(name, age):\n",
    "    print(f\"Hello {name}, you are {age} years old.\")\n",
    "person = {'name': 'Alice', 'age': 25}\n",
    "greet(**person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzj2M6mIeBrL",
    "outputId": "639d17f9-6112-4ba5-deba-54983010606c"
   },
   "outputs": [],
   "source": [
    "# Step 2: Extract token-level embeddings from BERT's last layer\n",
    "last_hidden_state = result1.last_hidden_state\n",
    "print(f\"Token embeddings shape: {last_hidden_state.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcuwBX65v5yW",
    "outputId": "ae6b98e7-9c92-43e2-a1ee-52b419b08c37"
   },
   "outputs": [],
   "source": [
    "# Step 3: Get attention mask (1 = real token, 0 = padding)\n",
    "attention_mask = encoded_input1[\"attention_mask\"]  # [1, 30]\n",
    "print(f\"Attention mask shape: {attention_mask.shape}\")\n",
    "print(\"\\n------------------------------------------\\n\")\n",
    "print(\"attention mask:\")\n",
    "print(attention_mask)\n",
    "print(\"\\n------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4puD2KXgFxP"
   },
   "outputs": [],
   "source": [
    "# Step 4: Zero out padding token embeddings\n",
    "# unsqueeze(-1) adds dimension: [1, 100] → [1, 100, 1]\n",
    "# This allows broadcasting when multiplying with embeddings [1, 100, 768]\n",
    "masked_embeddings = last_hidden_state * attention_mask.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Zkzr0T3gLHG"
   },
   "outputs": [],
   "source": [
    "# Step 5: Compute mean pooling (average of non-padding tokens)\n",
    "# Numerator: sum all 30 token embeddings\n",
    "sum_embeddings = masked_embeddings.sum(dim=1)  # [1, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9G7ClJGhwHq"
   },
   "outputs": [],
   "source": [
    "# Denominator: count how many real tokens\n",
    "num_real_tokens = attention_mask.sum(dim=1, keepdim=True)  # [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DzeMven2h0RU"
   },
   "outputs": [],
   "source": [
    "# Final sentence embedding: average of real token embeddings\n",
    "mean_embedding1 = sum_embeddings / num_real_tokens  # [1, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97okzrbov-Y6",
    "outputId": "593d22a2-da20-4abf-ff93-5c125da20342"
   },
   "outputs": [],
   "source": [
    "print(f\"Sentence embedding shape: {mean_embedding1.shape}\")\n",
    "print(\"\\n------------------------------------------\\n\")\n",
    "print(\"First Ten Elements of Embedding:\")\n",
    "print(mean_embedding1[0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "628854c4-2e5c-4154-a778-8976c3c558ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANszGqnUtrNY",
    "outputId": "b83c990d-3662-42e0-9cd8-6cd727b178d4"
   },
   "outputs": [],
   "source": [
    "# %% Now scale to ALL examples in the dataset\n",
    "import numpy as np\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to('cuda')\n",
    "\n",
    "batch_size = 32  # Process 32 texts at once\n",
    "all_embeddings = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_texts = df[\"text\"][i:i+batch_size].tolist()\n",
    "\n",
    "    # Tokenize the batch\n",
    "    encoded_input = tokenizer(batch_texts,\n",
    "                             max_length=30, # for speed\n",
    "                             padding=\"max_length\",\n",
    "                             truncation=True,\n",
    "                             return_tensors='pt').to('cuda')  # Move batch to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        result = model(**encoded_input)\n",
    "\n",
    "    last_hidden_state = result.last_hidden_state\n",
    "    attention_mask = encoded_input[\"attention_mask\"]\n",
    "    masked_embeddings = last_hidden_state * attention_mask.unsqueeze(-1)\n",
    "    mean_embedding = masked_embeddings.sum(dim=1) / attention_mask.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Move back to CPU and convert to numpy\n",
    "    batch_embeddings = mean_embedding.cpu().numpy()\n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "# stack into matrix\n",
    "embeddings_matrix = np.vstack(all_embeddings)\n",
    "\n",
    "print(f\"Embeddings matrix shape: {embeddings_matrix.shape}\")\n",
    "print(f\"Number of texts: {embeddings_matrix.shape[0]}\")\n",
    "print(f\"Embedding dimension: {embeddings_matrix.shape[1]}\")\n",
    "\n",
    "# Store in dataframe\n",
    "df['embedding'] = all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qCyNk56Ezviq",
    "outputId": "f06324f7-fd6f-49dd-daf5-91efb6b4afcf"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_encoder",
   "widgets": {}
  },
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
